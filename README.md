# ML-HT2
NLP kaggle competition

Выкладываю ноутбук (делал в collab, потом сохранил локально в IPYNB) с наилучшим f1.
В итоге private на Kaggle: 0,78273 (в рейтинг, почему-то попал бругой, чуть ниже)

![image](https://user-images.githubusercontent.com/113061480/206924035-f15be6d0-fb7f-43f4-8359-037c18a1465a.png)

Пробовал:
  - добавить в признаки длину фида, число слов в фиде
  - добавить в признаки банк через onehot
  - исключить одинаковые леммы из классов (оставить только уникальные для класса леммы)
  - попробовать подобрать другие классы (кроме 1 и 5), руководствуясь вероятностью результатов модели (predict_proba)
  - разные сочетания исключаемых букв/цифр/знаков из фидов перед лемматизацией
  - использовать разное разбиение на Н-граммы (униграммы показали лучший результат)


Не пробовал:
  - другие линейные и разрешенные модели для классификации (SVM, kNN..)
  - использовать время отзыва с разбиением на части суток (ближе к ночи, вероятно, оценки ниже)
  - прочее)

ПС: очень полезное ДЗ, хоть больше ~0,78 (public) выжать и не удалось, но получил много опыта: от настройки окружения и collab до всяких приемов ML и NLP. Интересно узнать секрет успеха чемпионов лидерборды.
